## KNN 
KNN是一种基本的回归与分类算法
- 分类问题：对新的样本，根据其 K 个最近邻的训练样本的类别，通过多数表决等方式进行预测 
- 回归问题：对新的样本，根据其 K 个最近邻的训练样本标签值的均值作为预测值  

### K邻近法的三要素 
- k值选择
- 距离度量
- 决策规则  

#### K值选择 
- k = 1时, 称为最邻近算法 
- 若k值较小，相当于**使用较小领域中的样本进行预测**, 偏差较小，方差较大
- 若k值较大，相当于**使用较大领域中的样本进行预测**, 偏差较大，方差较小 

#### 距离度量
k邻近模型的特征空间一般是 n 维实数向量空间,以 $L_p$ 表示：
$$
L_p(x_i, x_j) = (\sum_{l=1}^{n} |x_{i,l} - x_{j,l} | ^{p} ) ^{1/p} 
$$

#### 决策规则  
- 分类决策规则
    - 多数表决等价于经验风险最小化，$ \sum I(y_{i}==c_{m})$ 最大

- 回归决策规则  
    - 采用均值回归, 回归损失函数为均方误差 
    - 经验风险最小化化等价于均值误差最小 

### KD Tree 
- 实现 KNN 时，主要考虑: 如何对训练数据进行快速 $k$ 近邻搜索. 最简单的方法是 **线性扫描**，但当数据量很大时，非常耗时
- 解决方法：**使用 KD 树来提高 k邻近搜索效率**  


